{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "knowledge_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzQCYanwgf35",
        "colab_type": "text"
      },
      "source": [
        "# Knowledge distillation experiment in a Computer Vision task\n",
        "\n",
        "Inspired by Coursera programming task on recognizing hand signs (from 0 to 5), I decided to carry out the research on this task. The idea of my knowledge distillation experiment is the following:\n",
        " \n",
        "\n",
        "*   to learn a cumbersome model on training data\n",
        "*   the cumbersome model almost always produces the correct answer\n",
        "with very high confidence, but still much of the information about the learned function resides in the ratios of very small probabilities in the soft targets -> while learning it is essential to pay attention on the `Temperature` hyperparameter - it is applied to the softmax output of the model to increase the level of chaos in a system (to increase entropy) - to increase values and impact of small probabilities\n",
        "*   try to learn a simple NN model, that imitates the results of the cumbersome model on the same training set\n",
        "*   try to learn this simple model just as the cumbersome model(on the same X_train, Y_train)\n",
        "*   compare two approaches and see if knowledge distillation works\n",
        "\n",
        "\n",
        "Let's start with importing all nesessary tools and frameworks!\n",
        "\n",
        "I will use Keras to learn the cumbersome model - it is my realization of the famous NN model - ResNet50. Tensorflow.v1 will be used to learn a simple NN model (I have an experience of working with tf.v1 but not tf.v2, still it is not essential here).\n",
        "\n",
        "resnet_utils.py contains load_dataset() function (took this code and the dataset(h5 files) from Coursera), random_mini_batches_nn() (my realization,which I used to write earlier).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdxcnAtnsI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnet_utils import *\n",
        "from keras.initializers import glorot_uniform # Xavier initialization of weights\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "# from matplotlib.pyplot import imshow\n",
        "%matplotlib inline \n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.python.framework import ops\n",
        "tf.disable_eager_execution()\n",
        "tf.disable_v2_behavior()\n",
        "from resnet_utils import *\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last') #the last dimension in examples is a number of channels\n",
        "K.set_learning_phase(1) # training phase\n",
        "\n",
        "Temperature = 1000"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMdE7W1OuyR0",
        "colab_type": "text"
      },
      "source": [
        "I found it convenient to update the `Temperature` at the beginning. Small values (up to ~500) didn't work for my task, big values(from ~1200) didn't work as well. To my mind, it is connected with insufficient and excessive level of chaos in a system. The optimal `Temperature` to get more useful info from the output of the cumbersome model is ~1000.\n",
        "\n",
        "\n",
        "Let's move on to the realization of ResNet50!\n",
        "There are identity_block() and convolutional_block() functions below, which will be used in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisHpgC8nsJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: combine shortcut and main values - it is a main part of such residual block\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBt490ZnsJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: combine shortcut and main values - it is a main part of such residual block\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9Gf-SLy864",
        "colab_type": "text"
      },
      "source": [
        "Combine keras layers and residual blocks to an entire model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvnqFfwnsJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "    \n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.activations.softmax(X / Temperature, axis=-1)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yHEZ6jjzk4j",
        "colab_type": "text"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NGhz26pYnsJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG6onvapzqPI",
        "colab_type": "text"
      },
      "source": [
        "Upload datasets (not my code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXgRPxecnsJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "98c24565-835c-482c-88ef-60b3951c8692"
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnBL747t0iD8",
        "colab_type": "text"
      },
      "source": [
        "Number of epochs needed to achieve ~ 98% of accuracy on the test set is about 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vV5Y72ynsJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e7a88c2c-a775-486a-ba24-6f4451cfa0bb"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 2, batch_size = 64)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1080 samples\n",
            "Epoch 1/2\n",
            "1080/1080 [==============================] - 1s 1ms/sample - loss: 0.0674 - acc: 0.9907\n",
            "Epoch 2/2\n",
            "1080/1080 [==============================] - 1s 1ms/sample - loss: 0.0304 - acc: 0.9981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f869b330f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-PeTw2tnsJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c32ba308-d246-412b-e009-e53586b4d190"
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss = \" + str(preds[0]))\n",
        "print(\"Accuracy = \" + str(preds[1]))\n",
        "Y_predicted_train = model.predict(X_train)\n",
        "Y_train_nn = Y_predicted_train.T"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.0944771279891332\n",
            "Accuracy = 0.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlUdEDe3nsJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09a85243-13b3-4fc9-e070-12c349cb583c"
      },
      "source": [
        "print(Y_train_nn.shape)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 1080)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03In42htnsJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "dd110ce8-f99e-41ef-b5ff-4f4fbdc6f713"
      },
      "source": [
        "print(Y_train_nn)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.6171221e-03 9.9059922e-01 2.3609211e-03 ... 1.3828456e-03\n",
            "  1.3693939e-03 3.5242534e-03]\n",
            " [1.4668168e-03 2.2078133e-03 3.9379675e-02 ... 2.8643500e-02\n",
            "  2.8359675e-04 1.5177341e-03]\n",
            " [1.7710491e-03 1.3338482e-03 9.4604963e-01 ... 9.6354377e-01\n",
            "  1.3242408e-03 1.4060580e-03]\n",
            " [1.5705141e-03 1.6772916e-03 4.9259486e-03 ... 2.1711069e-03\n",
            "  5.8012077e-04 1.1845685e-03]\n",
            " [8.9386860e-03 2.3073286e-03 4.5774896e-03 ... 2.7508209e-03\n",
            "  9.9197769e-01 6.9082193e-03]\n",
            " [9.8263586e-01 1.8745080e-03 2.7063498e-03 ... 1.5079813e-03\n",
            "  4.4648619e-03 9.8545921e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNG85Ij109TX",
        "colab_type": "text"
      },
      "source": [
        "Here is the simple NN model comes in! Firstly, let's bring the train/test data to the appropriate view (not my code). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaHzZuofnsJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "d96deedb-732a-4a07-b6f4-4ff00c6e93d5"
      },
      "source": [
        "# Flatten the training and test images\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_flatten/255.\n",
        "X_test = X_test_flatten/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (12288, 1080)\n",
            "Y_train shape: (6, 1080)\n",
            "X_test shape: (12288, 120)\n",
            "Y_test shape: (6, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWvBq7a21i5T",
        "colab_type": "text"
      },
      "source": [
        "Define all needed functions to run a model. W1 - parameters of size[n_of_classes, image_size], where image_size = 64 * 64 * 3 = 12288, n_of_classes = 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTak4dnLnsJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, [n_x, None], name = 'X')\n",
        "    Y = tf.placeholder(tf.float32, [n_y, None], name = 'Y')\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "def initialize_parameters():\n",
        "    \n",
        "    tf.set_random_seed(1)\n",
        "    \n",
        "    W1 = tf.get_variable(\"W1\", [6,12288], initializer = tf.initializers.glorot_uniform(seed = 1))\n",
        "    b1 = tf.get_variable(\"b1\", [6,1], initializer = tf.zeros_initializer())\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1\n",
        "                 }\n",
        "    \n",
        "    return parameters\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                                                                          \n",
        "    \n",
        "    return Z1\n",
        " \n",
        "\n",
        "def compute_cost(Z1, Y):\n",
        "    \n",
        "    logits = tf.transpose(Z1)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    \n",
        "    return cost\n",
        "\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9puKbc_2toP",
        "colab_type": "text"
      },
      "source": [
        "Combine everything to a model_nn. I used this model to count parameters_soft(this NN imitates the cumbersome one) and parameters_hard(tries to learn independently from any models).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgm43h-OnsJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_nn(X_train, Y_train, X_test, Y_test, learning_rate = 0.00005,\n",
        "          num_epochs = 1500, minibatch_size = 64, print_cost = True):\n",
        "\n",
        "\n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    seed = 3\n",
        "    print(X_train.shape)\n",
        "    n_x, m = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                          # n_y : output size\n",
        "    costs = []                                      # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters() \n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                           # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches_nn(X_train, Y_train, minibatch_size, seed)\n",
        "            # learning_rate = learning_rate * 10 / (10 + epoch)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # The line that runs the graph on a minibatch\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
        "                \n",
        "                epoch_cost += minibatch_cost / minibatch_size\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per fives)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train_nn})) # change to Y_train when train parameters_hard\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh3izfYOnsKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "775f7bcf-09aa-4082-dfbd-8d63bd46f398"
      },
      "source": [
        "parameters_soft = model_nn(X_train, Y_train_nn, X_test, Y_test)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 1080)\n",
            "Cost after epoch 0: 0.486304\n",
            "Cost after epoch 100: 0.227813\n",
            "Cost after epoch 200: 0.174049\n",
            "Cost after epoch 300: 0.146294\n",
            "Cost after epoch 400: 0.125932\n",
            "Cost after epoch 500: 0.114637\n",
            "Cost after epoch 600: 0.102862\n",
            "Cost after epoch 700: 0.093877\n",
            "Cost after epoch 800: 0.087714\n",
            "Cost after epoch 900: 0.082321\n",
            "Cost after epoch 1000: 0.079291\n",
            "Cost after epoch 1100: 0.075892\n",
            "Cost after epoch 1200: 0.072563\n",
            "Cost after epoch 1300: 0.071233\n",
            "Cost after epoch 1400: 0.068499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.99722224\n",
            "Test Accuracy: 0.90833336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tcf90H4Gk5",
        "colab_type": "text"
      },
      "source": [
        "I've got maximum 92.5% of test accuracy, but the result changes over my trials and sometimes is not so good. However, I achieved ~ 92% several times, so let's consider this accuracy as final for imitating our cumbersome model.\n",
        "\n",
        "Let's change some parameters of model_nn(): learning_rate = 0.0001, num_epochs = 800 (enough for a simple model with big gradients in backprop), Y_train_nn change to Y_train at the end of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYXIp4SYnsKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7edf9c65-4bd6-4470-d7cc-622de2f84b42"
      },
      "source": [
        "parameters_hard = model_nn(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 1080)\n",
            "Cost after epoch 0: 0.486033\n",
            "Cost after epoch 100: 0.165543\n",
            "Cost after epoch 200: 0.105999\n",
            "Cost after epoch 300: 0.075136\n",
            "Cost after epoch 400: 0.055131\n",
            "Cost after epoch 500: 0.043367\n",
            "Cost after epoch 600: 0.033893\n",
            "Cost after epoch 700: 0.024959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.9990741\n",
            "Test Accuracy: 0.8833333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UO-ZGea5D1N",
        "colab_type": "text"
      },
      "source": [
        "Here I've got maximum 88% of test accuracy (and 87,5%, when the model was overfitted). For my simple model it seems like the highest accuracy, which can be achieved at current datasets(the model learned its maximum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE9TvCKF89O3",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "A cumbersome model (ResNet50 in my case) achieves significant results in recognizing hand signs. My first experiment(it is in the folder `failed experiments`) was conducted without `Temperature` hyperparameter and it allowed the model to train up to 99,...% of test accuracy. Unfortunately, the info from small probabilities in the output was very poor. That is why imitating model didn't work better than just simple one. `Temperature` increased entropy of the system, which helped small probabilities to prove themselves better. So, approximate results are the following:\n",
        "\n",
        "\n",
        "*   98% - test accuracy of the cumbersome model\n",
        "*   92% - test accuracy of the imitating model\n",
        "*   88% - test accuracy of the simple model\n",
        "\n",
        "Advantages of the imitating model:\n",
        "\n",
        "\n",
        "*   It gives better results on the test data (which can't be achieved by the simple model)\n",
        "*   It works on the test data much faster that the cumbersome model(it is not so noticeable at small datasets as mine - I have only 120 test examples)\n",
        "\n",
        "I decided to conduct an experiment with big amount of data(can be found in `failed experiments` folder). I found MNIST fashion dataset(60000 training pictures, 10000 test pictures, 10 classes, each image_size = 28 * 28 * 1 = 784). To my mind, the experiment failed, because the pictures' quality is very low - simple model can train on them no worse than the cumbersome model.\n",
        "\n",
        "\n",
        "# Can be better?\n",
        "\n",
        "Surely. I think, training on a big dataset will give an opportunity to an imitating model to give amazing performance on the test set. But the pictures' quality should be so good that a simple model can't give cool performance on the test set (can't learn so much info, features). It is a cool field to explore, by the way. Today I've decided to stop on my results, that show: knowledge distillation really works, an imitating model can be implemented in devices with unsufficient computational resources (especially in mobile phones without fast and stable connection to the Internet) and can show user/time-friendly performance!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}