{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "knowledge_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzQCYanwgf35",
        "colab_type": "text"
      },
      "source": [
        "# Knowledge distillation experiment in a Computer Vision problem\n",
        "\n",
        "Inspired by Coursera programming task on recognizing hand signs (from 0 to 5), I decided to carry out the research on this task. The idea of my knowledge distillation experiment is the following:\n",
        " \n",
        "\n",
        "*   to learn a cumbersome model on training data\n",
        "*   the cumbersome model almost always produces the correct answer\n",
        "with very high confidence, but still much of the information about the learned function resides in the ratios of very small probabilities in the soft targets -> while learning it is essential to pay attention on the `Temperature` hyperparameter - it is applied to the softmax output of the model to increase the level of chaos in a system (to increase entropy) - to increase values and impact of small probabilities\n",
        "*   try to learn a simple NN model, that imitates the results of the cumbersome model on the same training set\n",
        "*   try to learn this simple model just as the cumbersome model(on the same X_train, Y_train)\n",
        "*   compare two approaches and see if knowledge distillation works\n",
        "\n",
        "\n",
        "Let's start with importing all nesessary tools and frameworks!\n",
        "\n",
        "I will use Keras to learn the cumbersome model - it is my realization of the famous NN model - ResNet50. Tensorflow.v1 will be used to learn a simple NN model (I have an experience of working with tf.v1 but not tf.v2, still it is not essential here).\n",
        "\n",
        "resnet_utils.py contains load_dataset() function (took this code and the dataset(h5 files) from Coursera), random_mini_batches_nn() (my realization,which I used to write earlier).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdxcnAtnsI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnet_utils import *\n",
        "from keras.initializers import glorot_uniform # Xavier initialization of weights\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "# from matplotlib.pyplot import imshow\n",
        "%matplotlib inline \n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.python.framework import ops\n",
        "tf.disable_eager_execution()\n",
        "tf.disable_v2_behavior()\n",
        "from resnet_utils import *\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last') #the last dimension in examples is a number of channels\n",
        "K.set_learning_phase(1) # training phase\n",
        "\n",
        "Temperature = 1000"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMdE7W1OuyR0",
        "colab_type": "text"
      },
      "source": [
        "I found it convenient to update the `Temperature` at the beginning. Small values (up to ~500) didn't work for my task, big values(from ~1200) didn't work as well. To my mind, it is connected with insufficient and excessive level of chaos in a system. The optimal `Temperature` to get more useful info from the output of the cumbersome model is ~1000.\n",
        "\n",
        "\n",
        "Let's move on to the realization of ResNet50!\n",
        "There are identity_block() and convolutional_block() functions below, which will be used in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisHpgC8nsJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: combine shortcut and main values - it is a main part of such residual block\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBt490ZnsJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: combine shortcut and main values - it is a main part of such residual block\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9Gf-SLy864",
        "colab_type": "text"
      },
      "source": [
        "Combine keras layers and residual blocks to an entire model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvnqFfwnsJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "    \n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.activations.softmax(X / Temperature, axis=-1)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yHEZ6jjzk4j",
        "colab_type": "text"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NGhz26pYnsJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG6onvapzqPI",
        "colab_type": "text"
      },
      "source": [
        "Upload datasets (not my code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXgRPxecnsJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "df4b1918-c7df-4827-96ca-3277e2d73199"
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnBL747t0iD8",
        "colab_type": "text"
      },
      "source": [
        "Number of epochs needed to achieve ~ 98% of accuracy on the test set is about 70."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vV5Y72ynsJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "17e02404-c965-4b51-fa6d-db35b66d1a4c"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 70, batch_size = 64)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1080 samples\n",
            "Epoch 1/4\n",
            "1080/1080 [==============================] - 1s 1ms/sample - loss: 0.0222 - acc: 0.9954\n",
            "Epoch 2/4\n",
            " 128/1080 [==>...........................] - ETA: 0s - loss: 0.0091 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-ba1d6f9853d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3825\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-PeTw2tnsJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e11dedc-3820-4c9a-903e-8f436c886bc8"
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss = \" + str(preds[0]))\n",
        "print(\"Accuracy = \" + str(preds[1]))\n",
        "Y_predicted_train = model.predict(X_train)\n",
        "Y_train_nn = Y_predicted_train.T"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08346204782525699\n",
            "Accuracy = 0.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlUdEDe3nsJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17cbde89-55e4-484f-a15a-add516cc4a20"
      },
      "source": [
        "print(Y_train_nn.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 1080)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03In42htnsJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4d124273-82a7-46b1-ddc8-7723f8b9728c"
      },
      "source": [
        "print(Y_train_nn)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.7947179e-03 9.9498832e-01 5.1954254e-03 ... 2.5325054e-03\n",
            "  1.7384855e-03 3.0180456e-03]\n",
            " [1.1713703e-03 1.0195682e-03 2.9316185e-02 ... 1.8302143e-02\n",
            "  6.8036065e-04 1.0982596e-03]\n",
            " [1.1679714e-03 8.5650530e-04 9.4593859e-01 ... 9.7246087e-01\n",
            "  9.7452989e-04 9.7090378e-04]\n",
            " [1.6292720e-03 9.0219011e-04 9.7298687e-03 ... 2.8609415e-03\n",
            "  8.1157702e-04 1.0521575e-03]\n",
            " [9.2805410e-03 1.1080429e-03 5.6534149e-03 ... 2.2017148e-03\n",
            "  9.8766673e-01 7.6923184e-03]\n",
            " [9.8395616e-01 1.1254089e-03 4.1665197e-03 ... 1.6418244e-03\n",
            "  8.1283050e-03 9.8616832e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNG85Ij109TX",
        "colab_type": "text"
      },
      "source": [
        "Here is the simple NN model comes in! Firstly, let's bring the train/test data to the appropriate view (not my code). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaHzZuofnsJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9b60d612-4aaa-4fdc-bcca-1b085ddc3198"
      },
      "source": [
        "# Flatten the training and test images\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_flatten/255.\n",
        "X_test = X_test_flatten/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (12288, 1080)\n",
            "Y_train shape: (6, 1080)\n",
            "X_test shape: (12288, 120)\n",
            "Y_test shape: (6, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWvBq7a21i5T",
        "colab_type": "text"
      },
      "source": [
        "Define all needed functions to run a model. W1 - parameters of size[n_of_classes, image_size], where image_size = 64 * 64 * 3 = 12288, n_of_classes = 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTak4dnLnsJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, [n_x, None], name = 'X')\n",
        "    Y = tf.placeholder(tf.float32, [n_y, None], name = 'Y')\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "def initialize_parameters():\n",
        "    \n",
        "    tf.set_random_seed(1)\n",
        "    \n",
        "    W1 = tf.get_variable(\"W1\", [6,12288], initializer = tf.initializers.glorot_uniform(seed = 1))\n",
        "    b1 = tf.get_variable(\"b1\", [6,1], initializer = tf.zeros_initializer())\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1\n",
        "                 }\n",
        "    \n",
        "    return parameters\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                                                                          \n",
        "    \n",
        "    return Z1\n",
        " \n",
        "\n",
        "def compute_cost(Z1, Y):\n",
        "    \n",
        "    logits = tf.transpose(Z1)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    \n",
        "    return cost\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9puKbc_2toP",
        "colab_type": "text"
      },
      "source": [
        "Combine everything to a model_nn. I used this model to count parameters_soft(this NN imitates the cumbersome one) and parameters_hard(tries to learn independently from any models).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgm43h-OnsJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_nn(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 800, minibatch_size = 64, print_cost = True):\n",
        "\n",
        "\n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    seed = 3\n",
        "    print(X_train.shape)\n",
        "    n_x, m = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                          # n_y : output size\n",
        "    costs = []                                      # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters() \n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                           # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches_nn(X_train, Y_train, minibatch_size, seed)\n",
        "            # learning_rate = learning_rate * 10 / (10 + epoch)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # The line that runs the graph on a minibatch\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
        "                \n",
        "                epoch_cost += minibatch_cost / minibatch_size\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per fives)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh3izfYOnsKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "8e025f55-36b4-42c4-a961-93bd54f234cc"
      },
      "source": [
        "parameters_soft = model_nn(X_train, Y_train_nn, X_test, Y_test)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 1080)\n",
            "Cost after epoch 0: 0.484767\n",
            "Cost after epoch 100: 0.219910\n",
            "Cost after epoch 200: 0.162240\n",
            "Cost after epoch 300: 0.132405\n",
            "Cost after epoch 400: 0.110868\n",
            "Cost after epoch 500: 0.098246\n",
            "Cost after epoch 600: 0.086238\n",
            "Cost after epoch 700: 0.076537\n",
            "Cost after epoch 800: 0.069460\n",
            "Cost after epoch 900: 0.063148\n",
            "Cost after epoch 1000: 0.059083\n",
            "Cost after epoch 1100: 0.055874\n",
            "Cost after epoch 1200: 0.052359\n",
            "Cost after epoch 1300: 0.049892\n",
            "Cost after epoch 1400: 0.046928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.99814814\n",
            "Test Accuracy: 0.85833335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tcf90H4Gk5",
        "colab_type": "text"
      },
      "source": [
        "I've got maximum 92.5% of test accuracy, but the result changes over my trials and sometimes is not so good. However, I achieved ~ 92% several times, so let's consider this accuracy as final for imitating our cumbersome model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYXIp4SYnsKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7edf9c65-4bd6-4470-d7cc-622de2f84b42"
      },
      "source": [
        "parameters_hard = model_nn(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 1080)\n",
            "Cost after epoch 0: 0.486033\n",
            "Cost after epoch 100: 0.165543\n",
            "Cost after epoch 200: 0.105999\n",
            "Cost after epoch 300: 0.075136\n",
            "Cost after epoch 400: 0.055131\n",
            "Cost after epoch 500: 0.043367\n",
            "Cost after epoch 600: 0.033893\n",
            "Cost after epoch 700: 0.024959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.9990741\n",
            "Test Accuracy: 0.8833333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UO-ZGea5D1N",
        "colab_type": "text"
      },
      "source": [
        "Here I've got maximum 88% of test accuracy (and 87,5%, when the model was overfitted). For my simple model it seems like the highest accuracy, which can be achieved at current datasets(the model learned its maximum)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEQm_T6pnsKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}